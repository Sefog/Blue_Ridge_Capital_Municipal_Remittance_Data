{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Manager Municipal Remittance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "\n",
    "Extracted 1.5 GB of municipal real estate property manager financial information from an XLSX formatted file. \n",
    "\n",
    "Transformed the data by joining data across the 14 worksheets, removing duplicates and nulls, and grouping by Owner_Name.\n",
    "\n",
    "(Grouping is not entirely necessary at this point since multiple dimensions exist. The data will be focused, and unnecessary dimensions will be removed in step 2. However, this highlights the issue for discussion.)\n",
    "\n",
    "Loaded a new file from the cleaned data to reduce its size, extract, and better transform the data in step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = '7.14.24 UPIL.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Read all sheets into a dictionary of DataFrames\n",
    "dfs = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    # Read the sheet into a DataFrame\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name, header=0 if sheet_name == 'Sheet1' else None)\n",
    "    # Store the DataFrame in the dictionary\n",
    "    dfs[sheet_name] = df\n",
    "\n",
    "# Use the headers from 'Sheet1' for all DataFrames\n",
    "headers = dfs['Sheet1'].columns\n",
    "for sheet_name, df in dfs.items():\n",
    "    if sheet_name != 'Sheet1':\n",
    "        df.columns = headers\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(dfs.values(), ignore_index=True)\n",
    "\n",
    "# Clean 'Owner_Name' column\n",
    "combined_df['Owner_Name'] = combined_df['Owner_Name'].str.strip().str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Remove duplicates and nulls, then group by 'Owner_Name'\n",
    "cleaned_df = combined_df.drop_duplicates().dropna().groupby('Owner_Name').apply(lambda x: x) #needs agg\n",
    "\n",
    "# Write the cleaned DataFrame to a new Excel file\n",
    "cleaned_df.reset_index(drop=True).to_excel('cleaned_workbook.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "\n",
    "Cleaned raw data, consulting for next steps and finer points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the cleaned workbook\n",
    "cleaned_file_path = 'cleaned_workbook.xlsx'\n",
    "\n",
    "# Load the cleaned workbook\n",
    "df = pd.read_excel(cleaned_file_path)\n",
    "\n",
    "# Clean 'Owner_Name' column again to ensure consistency\n",
    "df['Owner_Name'] = df['Owner_Name'].str.strip().str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Define aggregation functions\n",
    "# Assuming the value to sum is in column 'Value' and other columns should keep their first occurrence\n",
    "agg_funcs = {\n",
    "    'Cash_Remitted' 'OwnerCount' 'Shares': 'sum',  # Replace 'Value' with the actual column name you want to sum\n",
    "    'Other_Info': 'first'  # Replace 'Other_Info' with actual non-numeric column names\n",
    "}\n",
    "\n",
    "# Group by 'Owner_Name' and aggregate\n",
    "grouped_df = df.groupby('Owner_Name').agg(agg_funcs).reset_index()\n",
    "\n",
    "# Write the grouped DataFrame to a new Excel file\n",
    "grouped_df.to_excel('grouped_cleaned_workbook.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
